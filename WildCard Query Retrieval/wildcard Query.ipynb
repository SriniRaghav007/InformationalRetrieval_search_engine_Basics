{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8df775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "400e8c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Arjun\n",
      "[nltk_data]     V\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e97196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abc6890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e617e2489abe9bca</td>\n",
       "      <td>\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250cf637294e09d</td>\n",
       "      <td>\"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1aa4592d5240ca</td>\n",
       "      <td>Marya Dzmitruk was born in Minsk, Belarus in M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48105766ff7f075b</td>\n",
       "      <td>\"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0543d4f82e5470b6</td>\n",
       "      <td>New Categories \\r\\n\\r\\nI honestly think that w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  e617e2489abe9bca  \"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...      0\n",
       "1  9250cf637294e09d  \"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...      0\n",
       "2  ce1aa4592d5240ca  Marya Dzmitruk was born in Minsk, Belarus in M...      0\n",
       "3  48105766ff7f075b      \"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"      0\n",
       "4  0543d4f82e5470b6  New Categories \\r\\n\\r\\nI honestly think that w...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359b6899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARJUNV~1\\AppData\\Local\\Temp/ipykernel_26168/1293593572.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"tokenized\"] = df['tokenized'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "df[\"tokenized\"] = df[\"comment_text\"]\n",
    "df = df.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x) \n",
    "df[\"tokenized\"] = df['tokenized'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421a89e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e617e2489abe9bca</td>\n",
       "      <td>\"\\r\\n\\r\\n a barnstar for you! \\r\\n\\r\\n  the de...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\n\\r\\n a barnstar for you \\r\\n\\r\\n  the defe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250cf637294e09d</td>\n",
       "      <td>\"\\r\\n\\r\\nthis seems unbalanced.  whatever i ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\n\\r\\nthis seems unbalanced  whatever i have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1aa4592d5240ca</td>\n",
       "      <td>marya dzmitruk was born in minsk, belarus in m...</td>\n",
       "      <td>0</td>\n",
       "      <td>marya dzmitruk was born in minsk belarus in ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48105766ff7f075b</td>\n",
       "      <td>\"\\r\\n\\r\\ntalkback\\r\\n\\r\\n dear celestia...  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\n\\r\\ntalkback\\r\\n\\r\\n dear celestia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0543d4f82e5470b6</td>\n",
       "      <td>new categories \\r\\n\\r\\ni honestly think that w...</td>\n",
       "      <td>0</td>\n",
       "      <td>new categories \\r\\n\\r\\ni honestly think that w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  e617e2489abe9bca  \"\\r\\n\\r\\n a barnstar for you! \\r\\n\\r\\n  the de...      0   \n",
       "1  9250cf637294e09d  \"\\r\\n\\r\\nthis seems unbalanced.  whatever i ha...      0   \n",
       "2  ce1aa4592d5240ca  marya dzmitruk was born in minsk, belarus in m...      0   \n",
       "3  48105766ff7f075b      \"\\r\\n\\r\\ntalkback\\r\\n\\r\\n dear celestia...  \"      0   \n",
       "4  0543d4f82e5470b6  new categories \\r\\n\\r\\ni honestly think that w...      0   \n",
       "\n",
       "                                           tokenized  \n",
       "0  \\r\\n\\r\\n a barnstar for you \\r\\n\\r\\n  the defe...  \n",
       "1  \\r\\n\\r\\nthis seems unbalanced  whatever i have...  \n",
       "2  marya dzmitruk was born in minsk belarus in ma...  \n",
       "3           \\r\\n\\r\\ntalkback\\r\\n\\r\\n dear celestia    \n",
       "4  new categories \\r\\n\\r\\ni honestly think that w...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f98441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [a, barnstar, for, you, the, defender, of, the...\n",
       "1    [this, seems, unbalanced, whatever, i, have, s...\n",
       "2    [marya, dzmitruk, was, born, in, minsk, belaru...\n",
       "3                           [talkback, dear, celestia]\n",
       "4    [new, categories, i, honestly, think, that, we...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokenized\"] = df[\"tokenized\"].apply(word_tokenize)\n",
    "df[\"tokenized\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b995784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Arjun\n",
      "[nltk_data]     V\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda words: [word for word in words if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9fb6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "df['stemmed'] = df['tokenized'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df4b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = pd.Series(df.stemmed.values,index=df.id).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d7fbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [barnstar, defend, wiki, barnstar, like, edit,...\n",
       "1    [seem, unbalanc, whatev, said, mathsci, said, ...\n",
       "2    [marya, dzmitruk, born, minsk, belaru, march, ...\n",
       "3                           [talkback, dear, celestia]\n",
       "4    [new, categori, honestli, think, need, add, ca...\n",
       "Name: stemmed, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = df[\"stemmed\"]\n",
    "my_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c5f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for key in my_dict:\n",
    "    for i in range(len(my_dict[key])):\n",
    "        term = my_dict[key][i]\n",
    "        words.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c517ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(my_list)\n",
    "inverted_index = {}\n",
    "for i in range(length):\n",
    "    check = my_list[i]\n",
    "    for item in words:\n",
    "        if item in check:\n",
    "            if item not in inverted_index:\n",
    "                inverted_index[item] = []\n",
    "            if item in inverted_index:\n",
    "                inverted_index[item].append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62dc9b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in inverted_index:\n",
    "    inverted_index[key] = list(set(inverted_index[key]))\n",
    "inverted_index[\"minsk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a891a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_query(query):\n",
    "  query = query.lower()\n",
    "\n",
    "  args = list(query.split(' '))\n",
    "\n",
    "  bool_q = ['and', 'or', 'not']\n",
    "  q_size = len(args)\n",
    "\n",
    "  \n",
    "  wildcard=[]\n",
    "\n",
    "  \n",
    "  for arg in args:\n",
    "    if \"*\" in arg:\n",
    "      wildcard.append(arg)\n",
    "  \n",
    "  \n",
    "  for i in range(len(args)):\n",
    "    if (args[i] not in bool_q) and (args[i] not in words) and (args[i] not in wildcard):\n",
    "      args[i]=spell_correction(words,args[i])\n",
    "\n",
    "  if args[0]=='not' and (q_size!=1) and (args[1] not in bool_q) and (args[1] not in wildcard):\n",
    "    ans = find_not(inverted_index[args[1]])\n",
    "    i=2\n",
    "  elif args[0]=='not' and q_size!=1 and (args[1] not in bool_q) and (args[1] in wildcard):\n",
    "    ans=find_not(wildcard_query(args[1]))\n",
    "    i=2\n",
    "  elif (args[0] not in bool_q) and (args[0] not in wildcard):\n",
    "    ans = inverted_index[args[0]]\n",
    "    i=1\n",
    "  elif (args[0] not in bool_q) and (args[0] in wildcard):\n",
    "    ans=wildcard_query(args[0])\n",
    "    i=1\n",
    "  else:\n",
    "    print(\"Invalid Query\")\n",
    "    return []\n",
    "  \n",
    "  while i<q_size-1:\n",
    "    if args[i]=='not' and (args[i+1] not in bool_q) and (args[i+1] not in wildcard):\n",
    "      ans = find_not(inverted_index[args[i+1]])\n",
    "      i+=2\n",
    "    elif args[i]=='not' and (args[i+1] not in bool_q) and (args[i+1] in wildcard):\n",
    "      ans=find_not(wildcard_query(args[i+1]))\n",
    "      i+=2\n",
    "    elif args[i]=='and' and args[i+1]!='not' and (args[i+1] not in wildcard):\n",
    "      ans = find_and(ans,inverted_index[args[i+1]])\n",
    "      i+=2\n",
    "    elif args[i]=='and' and args[i+1]!='not' and (args[i+1] in wildcard):\n",
    "      ans=find_and(ans,wildcard_query(args[i+1]))\n",
    "      i+=2\n",
    "    elif args[i]=='and' and (i<q_size-2) and (args[i+2] not in wildcard):\n",
    "      list1 = find_not(inverted_index[args[i+2]])\n",
    "      ans = find_and(ans,list1)\n",
    "      i+=3\n",
    "    elif args[i]=='and' and (i<q_size-2) and (args[i+2] in wildcard):\n",
    "      list1=find_not(wildcard_query(args[i+2]))\n",
    "      ans = find_and(ans,list1)\n",
    "      i+=3\n",
    "    elif args[i]=='or' and (args[i+1]!='not') and (args[i+1] not in wildcard):\n",
    "      ans = find_or(ans, inverted_index[args[i+1]])\n",
    "      i+=2\n",
    "    elif args[i]=='or' and (args[i+1]!='not') and (args[i+1] in wildcard):\n",
    "      ans= find_or(ans, wildcard_query(args[i+1]))\n",
    "      i+=2\n",
    "    elif args[i]=='or' and (i<q_size-2) and (args[i+2] not in wildcard):\n",
    "      list1 = find_not(inverted_index[args[i+2]])\n",
    "      ans = find_or(ans,list1)\n",
    "      i+=3\n",
    "    elif args[i]=='or' and (i<q_size-2) and (args[i+2] in wildcard):\n",
    "      list1=find_not(wildcard_query(args[i+2]))\n",
    "      ans=find_or(ans,list1)\n",
    "      i+=3\n",
    "    else:\n",
    "      print(\"Invalid Query\")\n",
    "      ans = []\n",
    "      break\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e78943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_match(query):\n",
    "  res=[]\n",
    "  for token in permuterm_index:\n",
    "    if token.startswith(query):\n",
    "      res.append(permuterm_index[token])\n",
    "  final_res=set(res)\n",
    "  return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5773ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_query(query):\n",
    "  query+='$'\n",
    "  length=len(query)\n",
    "  for d in range(length):\n",
    "    Rfirst = query[0 : len(query)-d]\n",
    "    Rsecond = query[len(query)-d : ]\n",
    "    rotated_query=Rsecond+Rfirst\n",
    "    if rotated_query[-1]=='*':\n",
    "      res=rotated_query\n",
    "      break\n",
    "  return res[:-1]\n",
    "\n",
    "def spell_correction(tokens,word):\n",
    "  edit_dist=10000000\n",
    "  for token in tokens:\n",
    "    dist=nltk.edit_distance(token,word)\n",
    "    if dist<edit_dist:\n",
    "      ans=token\n",
    "      edit_dist=dist\n",
    "    elif dist==edit_dist:\n",
    "      if len(inverted_index[token])>len(inverted_index[ans]):\n",
    "        ans=token\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ccf9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and(list1,list2):\n",
    "  result=list(set(list1) & set(list2))\n",
    "  return result\n",
    "\n",
    "def find_not(list1):\n",
    "  result=list(set(universal) - set(list1))\n",
    "  return result\n",
    "\n",
    "def find_or(list1,list2):\n",
    "  list1.extend(list2)\n",
    "  result=list(set(list1))\n",
    "  return result\n",
    "\n",
    "def permute(input):\n",
    "    tmp=input\n",
    "    s=len(input)+1\n",
    "    input+='$'+input\n",
    "    res=[]\n",
    "    for x in range(s):\n",
    "        res.append(input[x:x+s])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fedfaa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162279\n"
     ]
    }
   ],
   "source": [
    "permuterm_index={}\n",
    "\n",
    "def permuterm(tokens):\n",
    "  for token in tokens:\n",
    "    res=permute(token)\n",
    "    for item in res:\n",
    "      permuterm_index[item]=token\n",
    "\n",
    "permuterm(words)\n",
    "\n",
    "print(len(permuterm_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c82606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query:barnster and defender\n"
     ]
    }
   ],
   "source": [
    "user_query=input(\"Enter your query:\")\n",
    "results=boolean_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "449b4ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2392, 1]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf46b061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
